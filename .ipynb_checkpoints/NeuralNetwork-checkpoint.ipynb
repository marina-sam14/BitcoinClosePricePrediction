{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f562d1aa-4d2d-4337-9a31-3fc175480dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1797486f2d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d55b59-683f-48ba-bfe6-a523afc69235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (hidden1): Linear(in_features=50, out_features=25, bias=True)\n",
      "  (hidden2): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (out): Linear(in_features=25, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "####### Model Creation #######\n",
    "\n",
    "# Choose CPU or Cuda device (If capable GPU present).\n",
    "device = 'cpu'\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(50, 25) # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(25, 25) # hidden layer\n",
    "        self.out = torch.nn.Linear(25, 1)     # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.hidden1(x)) # activation function for first hidden layer\n",
    "        z = F.relu(self.hidden2(z)) # activation function for second hidden layer\n",
    "        z = self.out(z)        # linear output\n",
    "        return z\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d86b486-4a3f-4565-b7af-b500f1637e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1827, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>800.643982</td>\n",
       "      <td>834.281006</td>\n",
       "      <td>799.405029</td>\n",
       "      <td>834.281006</td>\n",
       "      <td>834.281006</td>\n",
       "      <td>155576000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>834.179993</td>\n",
       "      <td>875.781982</td>\n",
       "      <td>834.148987</td>\n",
       "      <td>864.539978</td>\n",
       "      <td>864.539978</td>\n",
       "      <td>200027008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>864.888000</td>\n",
       "      <td>925.117004</td>\n",
       "      <td>864.677002</td>\n",
       "      <td>921.984009</td>\n",
       "      <td>921.984009</td>\n",
       "      <td>275564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-24</td>\n",
       "      <td>922.179993</td>\n",
       "      <td>923.479004</td>\n",
       "      <td>886.335022</td>\n",
       "      <td>898.822021</td>\n",
       "      <td>898.822021</td>\n",
       "      <td>137727008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>899.651978</td>\n",
       "      <td>899.651978</td>\n",
       "      <td>862.424011</td>\n",
       "      <td>896.182983</td>\n",
       "      <td>896.182983</td>\n",
       "      <td>143664992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2016-12-21  800.643982  834.281006  799.405029  834.281006  834.281006   \n",
       "1  2016-12-22  834.179993  875.781982  834.148987  864.539978  864.539978   \n",
       "2  2016-12-23  864.888000  925.117004  864.677002  921.984009  921.984009   \n",
       "3  2016-12-24  922.179993  923.479004  886.335022  898.822021  898.822021   \n",
       "4  2016-12-25  899.651978  899.651978  862.424011  896.182983  896.182983   \n",
       "\n",
       "      Volume  \n",
       "0  155576000  \n",
       "1  200027008  \n",
       "2  275564000  \n",
       "3  137727008  \n",
       "4  143664992  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Dataset Loading #######\n",
    "dataset = pd.read_csv(\"Data/BTC-USD.csv\")\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac31c88b-3673-4192-ae70-ef7299be1369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\kkats\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.000846\n",
       "1       0.001299\n",
       "2       0.002159\n",
       "3       0.001813\n",
       "4       0.001773\n",
       "          ...   \n",
       "1822    0.680117\n",
       "1823    0.689799\n",
       "1824    0.687676\n",
       "1825    0.690270\n",
       "1826    0.715508\n",
       "Name: Close, Length: 1827, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Scaling #######\n",
    "scaled_data = dataset[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "scaler = MinMaxScaler(copy=False)\n",
    "scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "X = scaled_data['Close']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699fd896-d731-473e-8b07-4f6f1f8a90bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Data.Dataset):   \n",
    "    def __init__(self, data, window):\n",
    "        self.data = torch.Tensor(data.values)\n",
    "        self.window = window\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index:index+self.window], self.data[index+self.window])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.__len__() - (self.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba625c1-257a-42f9-ab92-179d0386d28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### Data Preperation #######\n",
    "split_ratio = 0.8\n",
    "train_size = floor(X.size*split_ratio)\n",
    "test_size = floor(X.size*(1-split_ratio))\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X[:train_size], 50)\n",
    "test_dataset = TimeSeriesDataset(X[train_size:], 50)\n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc367498-5bd2-4327-97a6-a604c5fa3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Training Function #######\n",
    "\n",
    "def train(dataset, model, loss_fn, optimizer):\n",
    "    size = len(dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataset):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X).squeeze(-1)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"loss: {loss:>7f}  Batch: [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f5559e1-849f-4fe6-acd1-a7b93327c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Testing Function #######\n",
    "\n",
    "def test(dataset, model, loss_fn):\n",
    "    size = len(dataset)\n",
    "    num_batches = len(dataset) - 50\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataset:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).squeeze(-1)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            testing_acc = torch.sum(pred == y)\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {testing_acc}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08df3943-67c7-48ca-9fdb-e4e1e9df9f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000010  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001191  Batch: [  300/ 1411]\n",
      "loss: 0.000160  Batch: [  400/ 1411]\n",
      "loss: 0.000069  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000090  Batch: [  700/ 1411]\n",
      "loss: 0.000005  Batch: [  800/ 1411]\n",
      "loss: 0.000006  Batch: [  900/ 1411]\n",
      "loss: 0.000002  Batch: [ 1000/ 1411]\n",
      "loss: 0.000022  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000039  Batch: [ 1300/ 1411]\n",
      "loss: 0.000142  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012374 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000011  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001182  Batch: [  300/ 1411]\n",
      "loss: 0.000159  Batch: [  400/ 1411]\n",
      "loss: 0.000069  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000090  Batch: [  700/ 1411]\n",
      "loss: 0.000005  Batch: [  800/ 1411]\n",
      "loss: 0.000005  Batch: [  900/ 1411]\n",
      "loss: 0.000002  Batch: [ 1000/ 1411]\n",
      "loss: 0.000022  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000039  Batch: [ 1300/ 1411]\n",
      "loss: 0.000142  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012333 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000012  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001172  Batch: [  300/ 1411]\n",
      "loss: 0.000158  Batch: [  400/ 1411]\n",
      "loss: 0.000068  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000089  Batch: [  700/ 1411]\n",
      "loss: 0.000005  Batch: [  800/ 1411]\n",
      "loss: 0.000005  Batch: [  900/ 1411]\n",
      "loss: 0.000002  Batch: [ 1000/ 1411]\n",
      "loss: 0.000021  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000040  Batch: [ 1300/ 1411]\n",
      "loss: 0.000141  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012292 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000013  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001162  Batch: [  300/ 1411]\n",
      "loss: 0.000157  Batch: [  400/ 1411]\n",
      "loss: 0.000068  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000089  Batch: [  700/ 1411]\n",
      "loss: 0.000005  Batch: [  800/ 1411]\n",
      "loss: 0.000004  Batch: [  900/ 1411]\n",
      "loss: 0.000002  Batch: [ 1000/ 1411]\n",
      "loss: 0.000021  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000040  Batch: [ 1300/ 1411]\n",
      "loss: 0.000141  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012250 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000014  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001153  Batch: [  300/ 1411]\n",
      "loss: 0.000156  Batch: [  400/ 1411]\n",
      "loss: 0.000068  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000088  Batch: [  700/ 1411]\n",
      "loss: 0.000005  Batch: [  800/ 1411]\n",
      "loss: 0.000004  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000021  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000040  Batch: [ 1300/ 1411]\n",
      "loss: 0.000140  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012208 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000016  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001144  Batch: [  300/ 1411]\n",
      "loss: 0.000155  Batch: [  400/ 1411]\n",
      "loss: 0.000067  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000088  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000004  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000020  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000041  Batch: [ 1300/ 1411]\n",
      "loss: 0.000140  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012175 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000017  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001135  Batch: [  300/ 1411]\n",
      "loss: 0.000154  Batch: [  400/ 1411]\n",
      "loss: 0.000067  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000088  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000003  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000020  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000041  Batch: [ 1300/ 1411]\n",
      "loss: 0.000139  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012142 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.000000  Batch: [    0/ 1411]\n",
      "loss: 0.000019  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001125  Batch: [  300/ 1411]\n",
      "loss: 0.000152  Batch: [  400/ 1411]\n",
      "loss: 0.000067  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000087  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000003  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000020  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000041  Batch: [ 1300/ 1411]\n",
      "loss: 0.000139  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012102 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.000001  Batch: [    0/ 1411]\n",
      "loss: 0.000020  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001117  Batch: [  300/ 1411]\n",
      "loss: 0.000151  Batch: [  400/ 1411]\n",
      "loss: 0.000067  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000087  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000003  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000020  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000042  Batch: [ 1300/ 1411]\n",
      "loss: 0.000138  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012058 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.000001  Batch: [    0/ 1411]\n",
      "loss: 0.000021  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001109  Batch: [  300/ 1411]\n",
      "loss: 0.000150  Batch: [  400/ 1411]\n",
      "loss: 0.000066  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000087  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000003  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000019  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000042  Batch: [ 1300/ 1411]\n",
      "loss: 0.000138  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.012033 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.000001  Batch: [    0/ 1411]\n",
      "loss: 0.000022  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001101  Batch: [  300/ 1411]\n",
      "loss: 0.000149  Batch: [  400/ 1411]\n",
      "loss: 0.000066  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000087  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000002  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000019  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000042  Batch: [ 1300/ 1411]\n",
      "loss: 0.000137  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011999 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.000001  Batch: [    0/ 1411]\n",
      "loss: 0.000023  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001094  Batch: [  300/ 1411]\n",
      "loss: 0.000148  Batch: [  400/ 1411]\n",
      "loss: 0.000066  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000086  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000002  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000019  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000043  Batch: [ 1300/ 1411]\n",
      "loss: 0.000137  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011960 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000002  Batch: [    0/ 1411]\n",
      "loss: 0.000024  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001088  Batch: [  300/ 1411]\n",
      "loss: 0.000147  Batch: [  400/ 1411]\n",
      "loss: 0.000066  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000086  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000002  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000019  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000043  Batch: [ 1300/ 1411]\n",
      "loss: 0.000137  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011918 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000002  Batch: [    0/ 1411]\n",
      "loss: 0.000025  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001082  Batch: [  300/ 1411]\n",
      "loss: 0.000146  Batch: [  400/ 1411]\n",
      "loss: 0.000065  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000086  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000002  Batch: [  900/ 1411]\n",
      "loss: 0.000001  Batch: [ 1000/ 1411]\n",
      "loss: 0.000018  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000043  Batch: [ 1300/ 1411]\n",
      "loss: 0.000136  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011870 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000002  Batch: [    0/ 1411]\n",
      "loss: 0.000026  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001076  Batch: [  300/ 1411]\n",
      "loss: 0.000145  Batch: [  400/ 1411]\n",
      "loss: 0.000065  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000086  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000001  Batch: [  900/ 1411]\n",
      "loss: 0.000000  Batch: [ 1000/ 1411]\n",
      "loss: 0.000018  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000044  Batch: [ 1300/ 1411]\n",
      "loss: 0.000136  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011820 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.000003  Batch: [    0/ 1411]\n",
      "loss: 0.000027  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001071  Batch: [  300/ 1411]\n",
      "loss: 0.000144  Batch: [  400/ 1411]\n",
      "loss: 0.000065  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000085  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000001  Batch: [  900/ 1411]\n",
      "loss: 0.000000  Batch: [ 1000/ 1411]\n",
      "loss: 0.000018  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000044  Batch: [ 1300/ 1411]\n",
      "loss: 0.000136  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011773 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000003  Batch: [    0/ 1411]\n",
      "loss: 0.000028  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001066  Batch: [  300/ 1411]\n",
      "loss: 0.000142  Batch: [  400/ 1411]\n",
      "loss: 0.000065  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000085  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000001  Batch: [  900/ 1411]\n",
      "loss: 0.000000  Batch: [ 1000/ 1411]\n",
      "loss: 0.000018  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000044  Batch: [ 1300/ 1411]\n",
      "loss: 0.000135  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011718 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.000004  Batch: [    0/ 1411]\n",
      "loss: 0.000028  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001060  Batch: [  300/ 1411]\n",
      "loss: 0.000141  Batch: [  400/ 1411]\n",
      "loss: 0.000064  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000085  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000001  Batch: [  900/ 1411]\n",
      "loss: 0.000000  Batch: [ 1000/ 1411]\n",
      "loss: 0.000018  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000044  Batch: [ 1300/ 1411]\n",
      "loss: 0.000135  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011666 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000004  Batch: [    0/ 1411]\n",
      "loss: 0.000028  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001055  Batch: [  300/ 1411]\n",
      "loss: 0.000140  Batch: [  400/ 1411]\n",
      "loss: 0.000064  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000084  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000001  Batch: [  900/ 1411]\n",
      "loss: 0.000000  Batch: [ 1000/ 1411]\n",
      "loss: 0.000017  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000045  Batch: [ 1300/ 1411]\n",
      "loss: 0.000135  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011612 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000005  Batch: [    0/ 1411]\n",
      "loss: 0.000028  Batch: [  100/ 1411]\n",
      "loss: 0.000010  Batch: [  200/ 1411]\n",
      "loss: 0.001050  Batch: [  300/ 1411]\n",
      "loss: 0.000139  Batch: [  400/ 1411]\n",
      "loss: 0.000064  Batch: [  500/ 1411]\n",
      "loss: 0.000002  Batch: [  600/ 1411]\n",
      "loss: 0.000084  Batch: [  700/ 1411]\n",
      "loss: 0.000006  Batch: [  800/ 1411]\n",
      "loss: 0.000001  Batch: [  900/ 1411]\n",
      "loss: 0.000000  Batch: [ 1000/ 1411]\n",
      "loss: 0.000017  Batch: [ 1100/ 1411]\n",
      "loss: 0.000079  Batch: [ 1200/ 1411]\n",
      "loss: 0.000045  Batch: [ 1300/ 1411]\n",
      "loss: 0.000134  Batch: [ 1400/ 1411]\n",
      "Test Error: \n",
      " Accuracy: 0%, Avg loss: 0.011557 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "####### Training #######\n",
    "EPOCHS = 20\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train(train_dataset, model, loss_fn, optimizer)\n",
    "    test(test_dataset, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7f2be-5c4e-40c9-8a35-f503011f1726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
