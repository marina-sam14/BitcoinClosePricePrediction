{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd4e6c5",
   "metadata": {},
   "source": [
    "### This notebook contains the first questions of our Assignment about Data Visualization, Cross Validation, Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6413669",
   "metadata": {},
   "source": [
    "##### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7f801",
   "metadata": {},
   "source": [
    "##### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8610fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data/BTC-USD.csv\")\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d041367",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e2944",
   "metadata": {},
   "source": [
    "We noticed that Close and Adj CLose columns are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761afda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset['Close'] - dataset['Adj Close']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd431a2",
   "metadata": {},
   "source": [
    "Open The price of the coin at the beginning of the trading day. </br>\n",
    "\n",
    "High: The highest price of the coin on a trading day. </br>\n",
    "\n",
    "Low: The lowest price of the coin on a trading day. </br>\n",
    "\n",
    "Close: The last price of the coin before the trading day ends. </br>\n",
    "\n",
    "Volume is the amount of a token traded in a specific time interval. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8ea3a",
   "metadata": {},
   "source": [
    "We converted Data column in datetime type to use it more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Date\"] = pd.to_datetime(dataset['Date'])\n",
    "dataset['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Year'] = dataset['Date'].dt.year\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f588f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b9ad0",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Close\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['pos_neg'] = dataset['Open'] - dataset['Close']\n",
    "dataset.head()\n",
    "#if Open > Close then 0,else 1\n",
    "dataset['Up/Down'] = np.where(dataset['pos_neg'] > 0, '0', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Up/Down'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8437ce2",
   "metadata": {},
   "source": [
    "That column contains only 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103b784",
   "metadata": {},
   "source": [
    "We have to check for NaN values in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b54498",
   "metadata": {},
   "source": [
    "In order to use MinMaxScaler, we have to check for zero values in our dataset because MinMaxScaler scales all the data features in the range [0, 1] or else in the range [-1, 1] if there are negative values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a13e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset['Open'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset['Close'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e1089",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset['High'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8464777",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset['Low'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset['Volume'] < 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bb1fd",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e600e36",
   "metadata": {},
   "source": [
    "We used the next formula to check the relationship between the variables and we ended to the conclusion that there is a strong relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.formula.ols(formula=\"Close ~ High + Low + Open\", data=dataset)\n",
    "multi_reg = model.fit()\n",
    "print(multi_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d395686",
   "metadata": {},
   "source": [
    "##### Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Close'].plot()\n",
    "plt.ylabel(\"Daily Bitcoin price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Close'].plot(style='k.',kind='hist')\n",
    "plt.title('Hisogram of closing price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = dataset['Close'].groupby(dataset['Year']).mean()\n",
    "by_year.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c458535",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot('Date', 'Volume', data=dataset)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Volume')\n",
    "plt.title('Volume trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = dataset.plot.scatter(x='Date', y='Close', c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc350ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = dataset.plot.scatter(x='Date',\n",
    "                      y='Volume',\n",
    "                      c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de2922",
   "metadata": {},
   "source": [
    "#### Dataset scaling\n",
    "We scaled our dataset using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b86921-5664-4b2a-966d-830e20ad2e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled_data = dataset[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "scaler = MinMaxScaler(copy=False)\n",
    "scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b66448",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data[\"Up/Down\"] = dataset[\"Up/Down\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].scatter(dataset.Close, dataset.Close)\n",
    "axes[0].set_title(\"Original data\")\n",
    "axes[1].scatter(scaled_data.Close, scaled_data.Close)\n",
    "axes[1].set_title(\"MinMax scaled data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdafbb0",
   "metadata": {},
   "source": [
    "Now we are ready to create our models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44a7a9",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef488ef",
   "metadata": {},
   "source": [
    "###### Creating X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef0d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_data[['Open', 'High', 'Low', 'Volume']]\n",
    "y = scaled_data['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35e96b",
   "metadata": {},
   "source": [
    "##### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82afec",
   "metadata": {},
   "source": [
    "##### Cross Validation Score and Predict Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "linReg = LinearRegression()\n",
    "scores = cross_val_score(linReg, X, y, scoring='r2', cv=cv, n_jobs=1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253beb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(linReg, X, y, cv=6)\n",
    "scores = cross_val_score(linReg, X, y, scoring='r2', cv=36, n_jobs=1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5800c493",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefbe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(y, predicted, edgecolors=(1, 1, 1))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], color='red')\n",
    "ax.set_xlabel('Expected ')\n",
    "ax.set_ylabel('Predicted ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plt.plot(scores)\n",
    "ax.set_xlabel('Folds')\n",
    "ax.set_ylabel('R2 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f619e",
   "metadata": {},
   "source": [
    "##### Training the Model using KFold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "scores = []\n",
    "errors = []\n",
    "i=1\n",
    "\n",
    "for training,testing in kf.split(X,y):\n",
    "    X_train,X_test = X.loc[training], X.loc[testing]\n",
    "    y_train,y_test = y.loc[training], y.loc[testing]\n",
    "    print ('{}/10 Folds {}'.format(i, kf.n_splits))\n",
    "    print('--------------------------')\n",
    "    \n",
    "    linReg = LinearRegression()\n",
    "    linReg.fit(X_train,y_train)\n",
    "    score = metrics.r2_score(y_test,linReg.predict(X_test))\n",
    "    error = metrics.mean_squared_error(y_test, linReg.predict(X_test))\n",
    "    print('R2 Score: ', score)\n",
    "    print('MSE: ', error)\n",
    "    scores.append(score)\n",
    "    errors.append(error)\n",
    "    print('\\n')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(errors)\n",
    "ax.set_xlabel('Folds')\n",
    "ax.set_ylabel('Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\", linReg.coef_)\n",
    "print(\"Intercept: \\n\", linReg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293f3bb",
   "metadata": {},
   "source": [
    "##### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179625c-5777-4547-9b97-f9fb8d7b9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin = linReg.predict(X_test)\n",
    "dfp = pd.DataFrame({'Actual_Price': y_test, 'Predicted_Price': y_pred_lin})\n",
    "dfp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc10c48",
   "metadata": {},
   "source": [
    "##### Polynomial Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c83ce-ccc9-4d0a-926d-d81e15c76247",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = linReg.coef_[0] * X_test['Open'] + linReg.coef_[1] * X_test['High'] + linReg.coef_[2] * X_test['Low'] + linReg.coef_[3] * X_test['Volume'] + linReg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450da51a",
   "metadata": {},
   "source": [
    "##### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684da402-b075-4004-a001-00284fb28ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, figsize=(12,12))\n",
    "plt.plot(np.linspace(0, y_test.size, y_test.size), y_test, color='red', label='Actual Data')\n",
    "plt.plot(np.linspace(0, y_test.size, y_test.size), y, label='Predicted Data')\n",
    "#plt.xlabel('Expected')\n",
    "#plt.ylabel('Predicted')\n",
    "plt.grid(color='#000000', linestyle='-', linewidth=0.5)\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4bfbd",
   "metadata": {},
   "source": [
    "##### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ecd8c-02e6-4028-b71f-92aced67ac23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(dfp['Actual_Price'], dfp['Predicted_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a185db",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_score = linReg.score(X_test, y_test)\n",
    "print(\"Linear Regression Score: \", reg_score)\n",
    "print(\"Absolute Squared Error: \", mean_absolute_error(y_test, y_pred_lin))\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "print(\"Mean Squared Error: \", mse_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37af9c7",
   "metadata": {},
   "source": [
    "As we can see, the score is extremely high and our model's predicitons are so different from the expected values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7b586",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3bd9fb",
   "metadata": {},
   "source": [
    "##### Creating X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_data[['Open', 'High', 'Low', 'Close','Volume']]\n",
    "y = dataset[\"Up/Down\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5bab5",
   "metadata": {},
   "source": [
    "##### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04fd892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c6c4c",
   "metadata": {},
   "source": [
    "##### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, X, y, scoring='roc_auc', cv=cv, n_jobs=1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(lr, X, y, cv=6)\n",
    "scores = cross_val_score(lr, X, y, scoring='roc_auc', cv=36, n_jobs=1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plt.plot(scores)\n",
    "ax.set_xlabel('Folds')\n",
    "ax.set_ylabel('AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e89105",
   "metadata": {},
   "source": [
    "##### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = lr.predict(X_test)\n",
    "dfp = pd.DataFrame({'Actual_Price': y_test, 'Predicted_Price': y_pred_log})\n",
    "dfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = lr.predict(X_test)\n",
    "y_pred_log_probs = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred_log)\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_log_probs)\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred_log))\n",
    "\n",
    "print('Testing AUC: ', test_auc_roc)\n",
    "\n",
    "print('Testing accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee9162",
   "metadata": {},
   "source": [
    "##### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metrics.roc_auc_score(y_test, lr.predict(X_test))\n",
    "error = metrics.log_loss(y_test, lr.predict(X_test))\n",
    "print('ROC AUC Score: ', score)\n",
    "print('Loss: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8c9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_log, digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcdb6c",
   "metadata": {},
   "source": [
    "As we can see, we are not satisfied from the score that Logistic Regression returns. </br>\n",
    "Next Step, Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b0c59-3499-497f-974c-666506ec3ce7",
   "metadata": {},
   "source": [
    "# **Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72482d1e-7cc9-4010-b18a-158dda89b620",
   "metadata": {},
   "source": [
    "##### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3a902-b66f-43c3-91eb-d8c755b99097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Visualize training history\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69da8a-4c1f-4cb9-b45e-4e1df194cbea",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb8584-e662-4022-a78e-76c4cbd7824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose CPU or Cuda device (If capable GPU present).\n",
    "device = 'cpu'\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(50, 25) # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(25, 25) # hidden layer\n",
    "        self.out = torch.nn.Linear(25, 1)      # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.hidden1(x)) # activation function for first hidden layer\n",
    "        z = F.relu(self.hidden2(z)) # activation function for second hidden layer\n",
    "        z = self.out(z)        # linear output\n",
    "        return z\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d1b80a-512b-445a-84db-aae54eabe36a",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2aebfe-038a-400d-839c-fad65a8897d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data/BTC-USD.csv\")\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ec6da-1b3e-4f5d-83bb-fe8a554614c4",
   "metadata": {},
   "source": [
    "#### Scaling Dataset \n",
    "We scaled our dataset using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79877b-9e46-4964-a965-349db84b52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = dataset[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "scaler = MinMaxScaler(copy=False)\n",
    "scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "X = scaled_data['Close']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05153995-3edd-4a52-bcdc-ab6df23d7037",
   "metadata": {},
   "source": [
    "In this moment, we had to create a TimeSeries function in order to create a scaling window. This windows helped us to create the batches for our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b24a0-6741-42d5-a691-4841b9d8f4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Data.Dataset):   \n",
    "    def __init__(self, data, window):\n",
    "        self.data = torch.Tensor(data.values)\n",
    "        self.window = window\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index:index+self.window], self.data[index+self.window])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.__len__() - (self.window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3dcbd-0cdd-4dea-818b-1bcb31d20510",
   "metadata": {},
   "source": [
    "#### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592583b4-aa77-4552-80ec-56ae31e821bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "train_size = floor(X.size*split_ratio)\n",
    "test_size = floor(X.size*(1-split_ratio))\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X[:train_size], 50)\n",
    "test_dataset = TimeSeriesDataset(X[train_size:], 50)\n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9203912-fce8-4694-8d89-94696af51b07",
   "metadata": {},
   "source": [
    "#### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6785da-8f31-4e93-8809-d6af4028735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, loss_fn, optimizer):\n",
    "    size = len(dataset)\n",
    "    tlosses = []\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataset):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X).squeeze(-1)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        tlosses.append(loss.item())\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"loss: {loss:>7f}  Batch: [{current:>5d}/{size:>5d}]\")\n",
    "    return tlosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabc898-04c0-4750-93f2-0d634bd83630",
   "metadata": {},
   "source": [
    "#### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f01956-fa47-49d0-ac6e-5b86ac986e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, model, loss_fn):\n",
    "    size = len(dataset)\n",
    "    vlosses = []\n",
    "    num_batches = len(dataset) - 50\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataset:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).squeeze(-1)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            vlosses.append(test_loss)\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    #print(f\"Avg Accuracy:  {1-test_loss:>8f} \\n\")\n",
    "    return vlosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc27e2-0c73-4129-bc41-d1c35d5d0045",
   "metadata": {},
   "source": [
    "#### Training the model for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d91499-364f-4e26-8632-46b5344ef3b4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "tlosses = []\n",
    "vlosses = []\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    etlosses = train(train_dataset, model, loss_fn, optimizer)\n",
    "    tlosses.append(sum(etlosses)/len(etlosses))\n",
    "    evlosses = test(test_dataset, model, loss_fn)\n",
    "    vlosses.append(sum(evlosses)/len(evlosses))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840cbf9-6fab-4db0-a7d4-9409d40cc30f",
   "metadata": {},
   "source": [
    "## Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032b895-8061-4bf4-bf33-7dad617a3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "data = dataset['Close']\n",
    "data = torch.Tensor(data[-50:].values)\n",
    "output = model(data)\n",
    "print(f'Predicted next-day price based on 50 previous ones: {output.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063c049-e6f1-4c35-86ff-de8a31d36225",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting Losses (Training and Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac2bbb-bb6c-446f-a6d7-0daf4d51595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, EPOCHS, EPOCHS), tlosses)\n",
    "plt.plot(np.linspace(1, EPOCHS, EPOCHS), vlosses) \n",
    "plt.legend(['Training Loss', 'Testing Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e57231-72b2-4d65-b699-6edfb10154a8",
   "metadata": {},
   "source": [
    "# **Comparing Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9367924-f77d-4dde-a32e-a155febdf2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compDf = pd.DataFrame({'Linear Regression': mse_lin, 'Logistic Regression': error, 'Neural Network': vlosses[-1]},index=[0])\n",
    "compDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636451ba",
   "metadata": {},
   "source": [
    "As we can see, Linear Regression has the best metrics. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
