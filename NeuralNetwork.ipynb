{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d340144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f562d1aa-4d2d-4337-9a31-3fc175480dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d55b59-683f-48ba-bfe6-a523afc69235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu device available!\n",
      "NeuralNetwork(\n",
      "  (hidden1): Linear(in_features=4, out_features=50, bias=True)\n",
      "  (hidden2): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (out): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "####### Model Creation #######\n",
    "\n",
    "# Get cpu or gpu device for training (If capable GPU present).\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device} device available!\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(4, 50) # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(50, 4) # hidden layer\n",
    "        self.out = torch.nn.Linear(4, 1)     # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.hidden1(x)) # activation function for first hidden layer\n",
    "        z = F.relu(self.hidden2(z)) # activation function for second hidden layer\n",
    "        z = self.out(z)        # linear output\n",
    "        return z\n",
    "\n",
    "model = NeuralNetwork().to('cpu')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d86b486-4a3f-4565-b7af-b500f1637e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1827, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>800.643982</td>\n",
       "      <td>834.281006</td>\n",
       "      <td>799.405029</td>\n",
       "      <td>834.281006</td>\n",
       "      <td>834.281006</td>\n",
       "      <td>155576000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>834.179993</td>\n",
       "      <td>875.781982</td>\n",
       "      <td>834.148987</td>\n",
       "      <td>864.539978</td>\n",
       "      <td>864.539978</td>\n",
       "      <td>200027008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>864.888000</td>\n",
       "      <td>925.117004</td>\n",
       "      <td>864.677002</td>\n",
       "      <td>921.984009</td>\n",
       "      <td>921.984009</td>\n",
       "      <td>275564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-24</td>\n",
       "      <td>922.179993</td>\n",
       "      <td>923.479004</td>\n",
       "      <td>886.335022</td>\n",
       "      <td>898.822021</td>\n",
       "      <td>898.822021</td>\n",
       "      <td>137727008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>899.651978</td>\n",
       "      <td>899.651978</td>\n",
       "      <td>862.424011</td>\n",
       "      <td>896.182983</td>\n",
       "      <td>896.182983</td>\n",
       "      <td>143664992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2016-12-21  800.643982  834.281006  799.405029  834.281006  834.281006   \n",
       "1  2016-12-22  834.179993  875.781982  834.148987  864.539978  864.539978   \n",
       "2  2016-12-23  864.888000  925.117004  864.677002  921.984009  921.984009   \n",
       "3  2016-12-24  922.179993  923.479004  886.335022  898.822021  898.822021   \n",
       "4  2016-12-25  899.651978  899.651978  862.424011  896.182983  896.182983   \n",
       "\n",
       "      Volume  \n",
       "0  155576000  \n",
       "1  200027008  \n",
       "2  275564000  \n",
       "3  137727008  \n",
       "4  143664992  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Dataset Loading #######\n",
    "\n",
    "dataset = pd.read_csv(\"Data/BTC-USD.csv\")\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac31c88b-3673-4192-ae70-ef7299be1369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Μαρίνα Σαμ\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.000219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>0.702042</td>\n",
       "      <td>0.694191</td>\n",
       "      <td>0.683605</td>\n",
       "      <td>0.680117</td>\n",
       "      <td>0.093591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>0.680560</td>\n",
       "      <td>0.684023</td>\n",
       "      <td>0.683304</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>0.690064</td>\n",
       "      <td>0.695438</td>\n",
       "      <td>0.697086</td>\n",
       "      <td>0.687676</td>\n",
       "      <td>0.071510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>0.687865</td>\n",
       "      <td>0.685316</td>\n",
       "      <td>0.683020</td>\n",
       "      <td>0.690270</td>\n",
       "      <td>0.088060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>0.692031</td>\n",
       "      <td>0.707539</td>\n",
       "      <td>0.700695</td>\n",
       "      <td>0.715508</td>\n",
       "      <td>0.087419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1827 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low     Close    Volume\n",
       "0     0.000381  0.000161  0.000665  0.000846  0.000270\n",
       "1     0.000884  0.000772  0.001195  0.001299  0.000397\n",
       "2     0.001343  0.001498  0.001660  0.002159  0.000612\n",
       "3     0.002201  0.001474  0.001990  0.001813  0.000219\n",
       "4     0.001864  0.001123  0.001625  0.001773  0.000236\n",
       "...        ...       ...       ...       ...       ...\n",
       "1822  0.702042  0.694191  0.683605  0.680117  0.093591\n",
       "1823  0.680560  0.684023  0.683304  0.689799  0.074200\n",
       "1824  0.690064  0.695438  0.697086  0.687676  0.071510\n",
       "1825  0.687865  0.685316  0.683020  0.690270  0.088060\n",
       "1826  0.692031  0.707539  0.700695  0.715508  0.087419\n",
       "\n",
       "[1827 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Scaling #######\n",
    "\n",
    "scaled_data = dataset[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "scaler = MinMaxScaler(copy=False)\n",
    "scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(scaled_data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1586649b-01db-4de6-a1f0-9176a8a8a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1461, 4])\n",
      "torch.Size([1461])\n",
      "torch.Size([366, 4])\n",
      "torch.Size([366])\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor(scaled_data[['Open', 'High', 'Low', 'Volume']].values)\n",
    "y = torch.Tensor(scaled_data['Close'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ba625c1-257a-42f9-ab92-179d0386d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Data Preperation #######\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "train_dataset = Data.TensorDataset(X_train, y_train)\n",
    "test_dataset = Data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False)\n",
    "\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc367498-5bd2-4327-97a6-a604c5fa3c91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Μαρίνα Σαμ\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Μαρίνα Σαμ\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    20] loss: 0.000\n",
      "[3,    20] loss: 0.000\n",
      "[4,    20] loss: 0.000\n",
      "[5,    20] loss: 0.000\n",
      "[6,    20] loss: 0.000\n",
      "[7,    20] loss: 0.000\n",
      "[8,    20] loss: 0.000\n",
      "[9,    20] loss: 0.000\n",
      "[10,    20] loss: 0.000\n",
      "[11,    20] loss: 0.000\n",
      "[12,    20] loss: 0.000\n",
      "[13,    20] loss: 0.000\n",
      "[14,    20] loss: 0.000\n",
      "[15,    20] loss: 0.000\n",
      "[16,    20] loss: 0.000\n",
      "[17,    20] loss: 0.000\n",
      "[18,    20] loss: 0.000\n",
      "[19,    20] loss: 0.000\n",
      "[20,    20] loss: 0.000\n",
      "[21,    20] loss: 0.000\n",
      "[22,    20] loss: 0.000\n",
      "[23,    20] loss: 0.000\n",
      "[24,    20] loss: 0.000\n",
      "[25,    20] loss: 0.000\n",
      "[26,    20] loss: 0.000\n",
      "[27,    20] loss: 0.000\n",
      "[28,    20] loss: 0.000\n",
      "[29,    20] loss: 0.000\n",
      "[30,    20] loss: 0.000\n",
      "[31,    20] loss: 0.000\n",
      "[32,    20] loss: 0.000\n",
      "[33,    20] loss: 0.000\n",
      "[34,    20] loss: 0.000\n",
      "[35,    20] loss: 0.000\n",
      "[36,    20] loss: 0.000\n",
      "[37,    20] loss: 0.000\n",
      "[38,    20] loss: 0.000\n",
      "[39,    20] loss: 0.000\n",
      "[40,    20] loss: 0.000\n",
      "[41,    20] loss: 0.000\n",
      "[42,    20] loss: 0.000\n",
      "[43,    20] loss: 0.000\n",
      "[44,    20] loss: 0.000\n",
      "[45,    20] loss: 0.000\n",
      "[46,    20] loss: 0.000\n",
      "[47,    20] loss: 0.000\n",
      "[48,    20] loss: 0.000\n",
      "[49,    20] loss: 0.000\n",
      "[50,    20] loss: 0.000\n",
      "[51,    20] loss: 0.000\n",
      "[52,    20] loss: 0.000\n",
      "[53,    20] loss: 0.000\n",
      "[54,    20] loss: 0.000\n",
      "[55,    20] loss: 0.000\n",
      "[56,    20] loss: 0.000\n",
      "[57,    20] loss: 0.000\n",
      "[58,    20] loss: 0.000\n",
      "[59,    20] loss: 0.000\n",
      "[60,    20] loss: 0.000\n",
      "[61,    20] loss: 0.000\n",
      "[62,    20] loss: 0.000\n",
      "[63,    20] loss: 0.000\n",
      "[64,    20] loss: 0.000\n",
      "[65,    20] loss: 0.000\n",
      "[66,    20] loss: 0.000\n",
      "[67,    20] loss: 0.000\n",
      "[68,    20] loss: 0.000\n",
      "[69,    20] loss: 0.000\n",
      "[70,    20] loss: 0.000\n",
      "[71,    20] loss: 0.000\n",
      "[72,    20] loss: 0.000\n",
      "[73,    20] loss: 0.000\n",
      "[74,    20] loss: 0.000\n",
      "[75,    20] loss: 0.000\n",
      "[76,    20] loss: 0.000\n",
      "[77,    20] loss: 0.000\n",
      "[78,    20] loss: 0.000\n",
      "[79,    20] loss: 0.000\n",
      "[80,    20] loss: 0.000\n",
      "[81,    20] loss: 0.000\n",
      "[82,    20] loss: 0.000\n",
      "[83,    20] loss: 0.000\n",
      "[84,    20] loss: 0.000\n",
      "[85,    20] loss: 0.000\n",
      "[86,    20] loss: 0.000\n",
      "[87,    20] loss: 0.000\n",
      "[88,    20] loss: 0.000\n",
      "[89,    20] loss: 0.000\n",
      "[90,    20] loss: 0.000\n",
      "[91,    20] loss: 0.000\n",
      "[92,    20] loss: 0.000\n",
      "[93,    20] loss: 0.000\n",
      "[94,    20] loss: 0.000\n",
      "[95,    20] loss: 0.000\n",
      "[96,    20] loss: 0.000\n",
      "[97,    20] loss: 0.000\n",
      "[98,    20] loss: 0.000\n",
      "[99,    20] loss: 0.000\n",
      "[100,    20] loss: 0.000\n",
      "[101,    20] loss: 0.000\n",
      "[102,    20] loss: 0.000\n",
      "[103,    20] loss: 0.000\n",
      "[104,    20] loss: 0.000\n",
      "[105,    20] loss: 0.000\n",
      "[106,    20] loss: 0.000\n",
      "[107,    20] loss: 0.000\n",
      "[108,    20] loss: 0.000\n",
      "[109,    20] loss: 0.000\n",
      "[110,    20] loss: 0.000\n",
      "[111,    20] loss: 0.000\n",
      "[112,    20] loss: 0.000\n",
      "[113,    20] loss: 0.000\n",
      "[114,    20] loss: 0.000\n",
      "[115,    20] loss: 0.000\n",
      "[116,    20] loss: 0.000\n",
      "[117,    20] loss: 0.000\n",
      "[118,    20] loss: 0.000\n",
      "[119,    20] loss: 0.000\n",
      "[120,    20] loss: 0.000\n",
      "[121,    20] loss: 0.000\n",
      "[122,    20] loss: 0.000\n",
      "[123,    20] loss: 0.000\n",
      "[124,    20] loss: 0.000\n",
      "[125,    20] loss: 0.000\n",
      "[126,    20] loss: 0.000\n",
      "[127,    20] loss: 0.000\n",
      "[128,    20] loss: 0.000\n",
      "[129,    20] loss: 0.000\n",
      "[130,    20] loss: 0.000\n",
      "[131,    20] loss: 0.000\n",
      "[132,    20] loss: 0.000\n",
      "[133,    20] loss: 0.000\n",
      "[134,    20] loss: 0.000\n",
      "[135,    20] loss: 0.000\n",
      "[136,    20] loss: 0.000\n",
      "[137,    20] loss: 0.000\n",
      "[138,    20] loss: 0.000\n",
      "[139,    20] loss: 0.000\n",
      "[140,    20] loss: 0.000\n",
      "[141,    20] loss: 0.000\n",
      "[142,    20] loss: 0.000\n",
      "[143,    20] loss: 0.000\n",
      "[144,    20] loss: 0.000\n",
      "[145,    20] loss: 0.000\n",
      "[146,    20] loss: 0.000\n",
      "[147,    20] loss: 0.000\n",
      "[148,    20] loss: 0.000\n",
      "[149,    20] loss: 0.000\n",
      "[150,    20] loss: 0.000\n",
      "[151,    20] loss: 0.000\n",
      "[152,    20] loss: 0.000\n",
      "[153,    20] loss: 0.000\n",
      "[154,    20] loss: 0.000\n",
      "[155,    20] loss: 0.000\n",
      "[156,    20] loss: 0.000\n",
      "[157,    20] loss: 0.000\n",
      "[158,    20] loss: 0.000\n",
      "[159,    20] loss: 0.000\n",
      "[160,    20] loss: 0.000\n",
      "[161,    20] loss: 0.000\n",
      "[162,    20] loss: 0.000\n",
      "[163,    20] loss: 0.000\n",
      "[164,    20] loss: 0.000\n",
      "[165,    20] loss: 0.000\n",
      "[166,    20] loss: 0.000\n",
      "[167,    20] loss: 0.000\n",
      "[168,    20] loss: 0.000\n",
      "[169,    20] loss: 0.000\n",
      "[170,    20] loss: 0.000\n",
      "[171,    20] loss: 0.000\n",
      "[172,    20] loss: 0.000\n",
      "[173,    20] loss: 0.000\n",
      "[174,    20] loss: 0.000\n",
      "[175,    20] loss: 0.000\n",
      "[176,    20] loss: 0.000\n",
      "[177,    20] loss: 0.000\n",
      "[178,    20] loss: 0.000\n",
      "[179,    20] loss: 0.000\n",
      "[180,    20] loss: 0.000\n",
      "[181,    20] loss: 0.000\n",
      "[182,    20] loss: 0.000\n",
      "[183,    20] loss: 0.000\n",
      "[184,    20] loss: 0.000\n",
      "[185,    20] loss: 0.000\n",
      "[186,    20] loss: 0.000\n",
      "[187,    20] loss: 0.000\n",
      "[188,    20] loss: 0.000\n",
      "[189,    20] loss: 0.000\n",
      "[190,    20] loss: 0.000\n",
      "[191,    20] loss: 0.000\n",
      "[192,    20] loss: 0.000\n",
      "[193,    20] loss: 0.000\n",
      "[194,    20] loss: 0.000\n",
      "[195,    20] loss: 0.000\n",
      "[196,    20] loss: 0.000\n",
      "[197,    20] loss: 0.000\n",
      "[198,    20] loss: 0.000\n",
      "[199,    20] loss: 0.000\n",
      "[200,    20] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "####### Training #######\n",
    "\n",
    "EPOCH = 200\n",
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader): # for each training step\n",
    "        \n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "\n",
    "        predictions = model(batch_x)           # input x and predict based on x\n",
    "        loss = loss_func(predictions, batch_y)  # calculate MSE based on x and y\n",
    "        loss.backward()                        # backpropagation, compute gradients\n",
    "        optimizer.step()                       # apply gradients to weights\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if step % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, step + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a09813-8ea3-4524-8879-8aaaf1340e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Testing #######\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
